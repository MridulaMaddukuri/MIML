{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mridula/Projects/MIML/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from typing import List, Set\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from deep_miml.models import Average, Attention\n",
    "from deep_miml.train import train_miml_model, test_multi_instance_model\n",
    "from deep_miml.utils import precision_recall_helper, get_avg_batch_precision_recall_at_k, timing\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YelpDataset:\n",
    "    def __init__(self, business_df, image_df, image_folder, transform):\n",
    "        self.business_df = business_df\n",
    "        self.image_df = image_df\n",
    "        self.transform = transform\n",
    "        self.image_folder = image_folder\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, i: int):\n",
    "        b_id = self.business_df.iloc[i]['business_id']\n",
    "        imgs = list(self.image_df[self.image_df['business_id'] == b_id]['photo_id'])\n",
    "        \n",
    "        imgs = [self.transform(Image.open(self.image_folder+f\"{img}.jpg\")) for img in imgs]\n",
    "        \n",
    "        labels = torch.FloatTensor(self.business_df.iloc[i,1:])\n",
    "        \n",
    "        return imgs, labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.business_df.shape[0]\n",
    "     \n",
    "        \n",
    "def collate_fn(batch, input_size=224):\n",
    "    img_lists, bag_labels = zip(*batch)\n",
    "\n",
    "    imgs = [img for img_list in img_lists for img in img_list]\n",
    "\n",
    "    sizes = torch.LongTensor([len(img_list) for img_list in img_lists])\n",
    "\n",
    "    bag_labels = torch.stack(bag_labels)\n",
    "    \n",
    "\n",
    "    if len(imgs) != 0:\n",
    "        imgs = torch.stack(imgs)\n",
    "    else:\n",
    "        imgs = torch.zeros((0, 3, input_size, input_size)).float()\n",
    "\n",
    "    return imgs, sizes, bag_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of business_df (23137, 9)\n",
      "Shape of images_df (139443, 2)\n"
     ]
    }
   ],
   "source": [
    "images_folder_path = '../../WIML/yelp_data/website_data/yelp_photos/photos/'\n",
    "final_business_df = pd.read_csv('../../WIML/yelp_data/website_data/final_business_data.csv')\n",
    "final_images_df = pd.read_csv('../../WIML/yelp_data/website_data/final_images_data.csv')\n",
    "\n",
    "print(f'Shape of business_df {final_business_df.shape}')\n",
    "print(f'Shape of images_df {final_images_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16785, 2)\n",
      "(16561, 2)\n"
     ]
    }
   ],
   "source": [
    "full_business_list = final_images_df.groupby(['business_id'])['photo_id'].count().reset_index()\n",
    "full_business_list = full_business_list[full_business_list.photo_id > 1]\n",
    "print(full_business_list.shape)\n",
    "full_business_list = full_business_list[full_business_list.photo_id < 50]\n",
    "print(full_business_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results for reproducability \n",
    "full_business_list = set(full_business_list.business_id)\n",
    "\n",
    "test_business_list = random.sample(full_business_list,500)\n",
    "val_business_list = random.sample(full_business_list.difference(test_business_list), 1000)\n",
    "train_business_list = full_business_list.difference(test_business_list+val_business_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "image_datasets = {}\n",
    "\n",
    "image_datasets['train'] = YelpDataset(business_df= final_business_df[final_business_df.business_id.isin(train_business_list)],\n",
    "                           image_df= final_images_df,\n",
    "                           image_folder = images_folder_path,\n",
    "                           transform= data_transforms['train'])\n",
    "\n",
    "image_datasets['val'] = YelpDataset(business_df= final_business_df[final_business_df.business_id.isin(val_business_list)],\n",
    "                         image_df= final_images_df,\n",
    "                          image_folder = images_folder_path,\n",
    "                         transform = data_transforms['val'])\n",
    "\n",
    "image_datasets['test'] = YelpDataset(business_df= final_business_df[final_business_df.business_id.isin(test_business_list)],\n",
    "                         image_df= final_images_df,\n",
    "                          image_folder = images_folder_path,\n",
    "                         transform = data_transforms['test'])\n",
    "\n",
    "# print( f'len of train dataset {train_dataset.__len__()}')\n",
    "# print( f'len of val dataset {val_dataset.__len__()}')\n",
    "# train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet18'\n",
    "num_categories = 8\n",
    "model_type = 'avg'\n",
    "lr = 0.0001\n",
    "\n",
    "use_pretrained = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders ready ... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                                    batch_size= 4,\n",
    "                                                    shuffle=(x == 'train'),\n",
    "                                                    num_workers= 12,\n",
    "                                                    collate_fn=collate_fn)\n",
    "                    for x in ['train', 'val','test']}\n",
    "\n",
    "print('DataLoaders ready ... \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_and_save(model_type,model_name, lr, device, num_epochs= 1,\n",
    "                   early_stopping= True, save_folder = '../temp/', patience =5):\n",
    "\n",
    "    if model_type == 'avg':\n",
    "        model_ft = Average(num_classes = num_categories,model_name= model_name)\n",
    "    elif model_type == 'attention':\n",
    "        model_ft = Attention(num_classes = num_categories, model_name= model_name)\n",
    "\n",
    "    else:\n",
    "        print(\"Enter valid model type\")\n",
    "        exit(0)\n",
    "\n",
    "\n",
    "        # Send the model to GPU\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "        # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr= lr)\n",
    "\n",
    "    # You should pass logits to nn.BCEwithLogitsLoss and probabilities (using \"sigmoid\") to nn.BCELoss.\n",
    "    # Using BCEWithLogitsLoss because it is more stable \n",
    "    criterion = torch.nn.BCEWithLogitsLoss(weight=None, reduction='mean')\n",
    "\n",
    "        # Train and evaluate\n",
    "    model_ft = train_miml_model(model=model_ft,\n",
    "                                device = device,\n",
    "                                dataloaders=dataloaders_dict,\n",
    "                                criterion=criterion,\n",
    "                                optimizer=optimizer_ft,\n",
    "                                save_folder= save_folder ,\n",
    "                                num_epochs= num_epochs,\n",
    "                                early_stopping = early_stopping,\n",
    "                                patience = patience\n",
    "                                )\n",
    "\n",
    "    torch.save(model_ft.state_dict(),\n",
    "        Path.cwd().joinpath(save_folder,\"yelp_{}_{}_pretrained_{}.pt\".format(model_name, model_type, use_pretrained)))\n",
    "    \n",
    "    return model_ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "result = test_multi_instance_model(model_ft, device, dataloaders_dict['test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miml",
   "language": "python",
   "name": "miml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
